/*
  ==============================================================================

    This file was auto-generated by the Jucer!

    It contains the basic startup code for a Juce application.

  ==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"
#include "OneVoice.h"

AudioProcessor* JUCE_CALLTYPE createPluginFilter();


//==============================================================================
/** A demo synth sound that's just a basic sine wave.. */
class FMSound : public SynthesiserSound
{
public:
    FMSound() {}

    bool appliesToNote (int /*midiNoteNumber*/) override  { return true; }
    bool appliesToChannel (int /*midiChannel*/) override  { return true; }
};

//==============================================================================
/** A simple demo synth voice that just plays a sine wave.. */
struct SineWaveVoice  : public SynthesiserVoice
{
public:
    SineWaveVoice()
    : envelope(0.0),
    onOff (false),
    tailOff(true)
    {
        //        carrier.setSamplingRate(getSampleRate());
        //        modulator.setSamplingRate(getSampleRate());
        //        oneVoice.setSamplingRate(getSampleRate());
        oneVoice.init(getSampleRate());
        oneVoice.buildUserInterface(&voiceControl);
        audioBuffer = new float*[2];
    };
    
    bool canPlaySound (SynthesiserSound* sound) override
    {
        return dynamic_cast<FMSound*> (sound) != nullptr;
    }
    
    void startNote (int midiNoteNumber, float velocity,
                    SynthesiserSound*, int /*currentPitchWheelPosition*/) override
    {
        // converting MIDI note number into freq
        voiceControl.setParamValue("/voice/freq", MidiMessage::getMidiNoteInHertz(midiNoteNumber));
        
        //        carrierFrequency = MidiMessage::getMidiNoteInHertz(midiNoteNumber);
        
        // we don't want an ugly sweep when the note begins...
        //        smooth[0].setSmooth(0);
        //        smooth[0].tick(carrierFrequency);
        
        // standard smoothing...
        //        for(int i=0; i<2; i++){
        //            smooth[i].setSmooth(0.999);
        //        }
        
        voiceControl.setParamValue("/voice/gain", velocity);
        voiceControl.setParamValue("/voice/trig", 1);
        //       envelope = 1;
        
        //        level = velocity;
        // level = pow(velocity,2); // if we want linear dynamic
        
        // tells the note to begin!
        onOff = true;
        
        // These parameters could be controlled with UI elements and could
        // be assigned to specific MIDI controllers. If you do so,
        // don't forget to smooth them!
        //       modulator.setFrequency(1000.0);
        //       index = 150;
    }
    
    void stopNote (float /*velocity*/, bool allowTailOff) override
    {
        onOff = false; // end the note
        //       level = 0; // ramp envelope to 0 if tail off is allowed
        voiceControl.setParamValue("/voice/trig", 0);
        
        tailOff = allowTailOff;
    }
    
    void pitchWheelMoved (int newValue) override
    {
//        DBG("pitchbend: " << newValue);
//        voiceControl.setParamValue("/voice/pitchBend", newValue/16383*4+2);
        // Pitch wheel is an important standard MIDI feature that should be implemented
    }
    
    void controllerMoved (int controllerNumber, int newValue) override
    {
        
//        if(controllerNumber == 1) {
//            voiceControl.setParamValue("/voice/modWheel", newValue/127);
//            DBG("ModWheel moved");
//             }
//        if(controllerNumber != 1 && learning == 1) {
//            assignCC = controllerNumber;
//            DBG("AssignCC = " << assignCC);
//            
//        }
//        if(controllerNumber == attackCC){
//                voiceControl.setParamValue("/voice/att",newValue/127*1.99+0.01);
//        }
//        if(controllerNumber == decayCC) {
//                voiceControl.setParamValue("/voice/del",newValue/127*1.99+0.01);
//        }
//        if(controllerNumber == sustainCC) {
//                voiceControl.setParamValue("/voice/sus",newValue/127*100);
//        }
//        if(controllerNumber == releaseCC) {
//                voiceControl.setParamValue("/voice/rel",newValue/127*3.999+0.001);
//        }
//        if(controllerNumber == cutoffCC) {
//                voiceControl.setParamValue("/voice/cutoff",newValue/127*7980+20);
//        }
//        if(controllerNumber == QCC) {
//                voiceControl.setParamValue("/voice/Q",newValue/127*19+1);
//        }
//        if(controllerNumber == vibratoRateCC) {
//            voiceControl.setParamValue("/voice/vibrate",newValue/127*10+2);
//        }
//        if(controllerNumber == vibratoPhaseCC) {
//                voiceControl.setParamValue("/voice/vibPhase",newValue/127);
//        }
//        if(controllerNumber == vibratoStrengthCC) {
//                voiceControl.setParamValue("/voice/vibStr",newValue/127);
//        }
//        if(controllerNumber == tremeloRateCC) {
//                voiceControl.setParamValue("/voice/tremrate",newValue/127*10+2);
//        }
//        if(controllerNumber == tremeloPhaseCC) {
//                voiceControl.setParamValue("/voice/tremPhase",newValue/127);
//        }
//        if(controllerNumber== tremeloStrengthCC) {
//                voiceControl.setParamValue("/voice/tremstr",newValue/127);
//        }

        
        //        DBG("Controller #: " << controllerNumber);
        //        DBG("Value: " << newValue);
        
        //        if(!midiLearn) {
        //            if(controllerNumber == attackCC){
        //                DBG("New Attack Value: " << (float)newValue/127*1.99+0.01);
        //             //   faustParameterChanged("attack", (float)newValue/127*1.99+0.01);
        //            }
        //        }
        //        if(controllerNumber== decayCC)
        //            decaySlider.setValue(message.getControllerValue()/127*1.99+0.01);
        //        if(message.getControllerNumber() == sustainCC)
        //            sustainSlider.setValue(message.getControllerValue()/127*100);
        //        if(message.getControllerNumber() == releaseCC)
        //            releaseSlider.setValue(message.getControllerValue()/127*3.999+0.001);
        //        if(message.getControllerNumber() == cutoffCC)
        //            cutoffSlider.setValue(message.getControllerValue()/127*7980+20);
        //        if(message.getControllerNumber() == QCC)
        //            QSlider.setValue(message.getControllerValue()/127*19+1);
        //        if(message.getControllerNumber() == vibratoRateCC)
        //            vibratoRateSlider.setValue(message.getControllerValue()/127*10+2);
        //        if(message.getControllerNumber() == vibratoPhaseCC)
        //            vibratoPhaseSlider.setValue(message.getControllerValue()/127);
        //        if(message.getControllerNumber() == vibratoStrengthCC)
        //            vibratoStrengthSlider.setValue(message.getControllerValue()/127);
        //        if(message.getControllerNumber() == tremeloRateCC)
        //            tremeloRateSlider.setValue(message.getControllerValue()/127*10+2);
        //        if(message.getControllerNumber() == tremeloPhaseCC)
        //            tremeloPhaseSlider.setValue(message.getControllerValue()/127);
        //        if(message.getControllerNumber() == tremeloStrengthCC)
        //            tremeloStrengthSlider.setValue(message.getControllerValue()/127);
        
    }
    
    void renderNextBlock (AudioSampleBuffer& outputBuffer, int startSample, int numSamples) override
    {
        // only compute block if note is on!
        if(envelope != 0 || onOff){
            audioBuffer[0]= new float[numSamples];
            audioBuffer[1]= new float[numSamples];
            oneVoice.compute(numSamples, NULL, audioBuffer);
            envelope = audioBuffer[1][numSamples-1];
            //            while (--numSamples >= 0){
            //                envelope = smooth[1].tick(level); // here we use a smoother as an envelope generator
            //                carrier.setFrequency(smooth[0].tick(carrierFrequency) + modulator.tick()*index);
            //                const float currentSample = (float) carrier.tick() * envelope;
            for (int j = 0; j < numSamples; ++j) {
                for (int i = outputBuffer.getNumChannels(); --i >= 0;){
                    
                    outputBuffer.addSample (i, startSample, audioBuffer[0][j]);
                }
                
                //outputBuffer.copyFrom(i, startSample, audioBuffer[0], numSamples);
                //  outputBuffer.addSample (i, startSample, currentSample);
                
                ++startSample;
            }
            // if tail off is disabled, we end the note right away, otherwise, we wait for envelope
            // to reach a safe value
            if(!onOff && (envelope < 0.001 || !tailOff)){
                envelope = 0;
                clearCurrentNote();
            }
 //                 DBG("Sample 0: " << audioBuffer[0][0]);
        }
  
    }
    
    
    
    // might have to add to juce_Synthesiser.h if you save in projucer:
    // virtual void faustParameterChanged (String parameterName, float newParameterValue);
    // and to juce_Synthesiser.cpp
    // void SynthesiserVoice::faustParameterChanged(juce::String, float) {}
    void faustParameterChanged (String parameterName, float newParameterValue) override {
        
        if(parameterName == "attack") {
//            if(learning==1) {
//                attackCC = assignCC;
//                DBG("AttackCC = " << attackCC);
//            }
//            else
                voiceControl.setParamValue("/voice/att", newParameterValue);
//            DBG("New Attack Value: " << newParameterValue);
        }
        if(parameterName == "decay") {
//            if(learning==1)
//                decayCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/del", newParameterValue);
        }
        if(parameterName == "sustain") {
//            if(learning)
//                sustainCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/sus", newParameterValue);
        }
        if(parameterName == "release") {
//            if(learning)
//                releaseCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/rel", newParameterValue);
        }
        if(parameterName == "cutoff"){
//            if(learning)
//                cutoffCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/cutoff", newParameterValue);
        }
        if(parameterName == "Q") {
//            if(learning)
//                QCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/Q", newParameterValue);
        }
        if(parameterName == "vibRate") {
//            if(learning)
//                vibratoRateCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/vibrate", newParameterValue);
        }
        if(parameterName == "vibStr") {
//            if(learning)
//                vibratoStrengthCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/vibstr", newParameterValue);
        }
        if(parameterName == "vibPhase") {
//            if(learning)
//                vibratoPhaseCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/vibPhase", newParameterValue);
        }
        if(parameterName == "tremRate") {
//            if(learning)
//                tremeloRateCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/tremrate", newParameterValue);
        }
        if(parameterName == "tremStr") {
//            if(learning)
//                tremeloStrengthCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/tremstr", newParameterValue);
        }
        if(parameterName == "tremPhase") {
//            if(learning)
//                tremeloPhaseCC = assignCC;
//            else
                voiceControl.setParamValue("/voice/tremPhase", newParameterValue);
        }
        if(parameterName == "tremOn") {
            voiceControl.setParamValue("/voice/tremOn", newParameterValue);
        }
        if(parameterName == "vibOn") {
            voiceControl.setParamValue("/voice/vibOn", newParameterValue);
        }
        if(parameterName == "modWheel") {
            voiceControl.setParamValue("/voice/modWheel", newParameterValue);
        }
        if(parameterName == "tremMWOn") {
            voiceControl.setParamValue("/voice/tremMWOn", newParameterValue);
        }
        if(parameterName == "vibMWOn") {
            voiceControl.setParamValue("/voice/vibMWOn", newParameterValue);
        }
        if(parameterName == "pitchBend") {
            voiceControl.setParamValue("/voice/pitchBend", newParameterValue);
        }
//        if(parameterName == "midiLearn") {
//            learning = (bool) newParameterValue;
//            DBG("Learning: " << learning);
//            assignCC = 128;
//        }
    //        if(parameterName == "midiLearn")
    //            midiLearn = (bool)newParameterValue;
//            if(parameterName == "attackCC") {
//                attackCC = newParameterValue;
//                DBG("Voice attackCC = " << attackCC);
//            }
    
    }
    
    public:
//        int assignCC=128;
//        int attackCC=128;
//        int decayCC=128;
//        int sustainCC=128;
//        int releaseCC=128;
//        int cutoffCC=128;
//        int QCC=128;
//        int vibratoRateCC=128;
//        int vibratoPhaseCC=128;
//        int vibratoStrengthCC=128;
//        int tremeloRateCC=128;
//        int tremeloPhaseCC=128;
//        int tremeloStrengthCC=128;
//        int learning;
    
    
private:
    
    
    
    float** audioBuffer;
    OneVoice oneVoice;
    MapUI voiceControl;
    //    Sine carrier, modulator;
    //    Smooth smooth[2];
    double envelope;
    bool onOff, tailOff;
};


//==============================================================================
JuceDemoPluginAudioProcessor::JuceDemoPluginAudioProcessor()
    : lastUIWidth (600),
      lastUIHeight (400),
assignCC(128),
attackCC(128),
decayCC(128),
sustainCC(128),
releaseCC(128),
cutoffCC(128),
QCC(128),
vibratoRateCC(128),
vibratoPhaseCC(128),
vibratoStrengthCC(128),
tremeloRateCC(128),
tremeloPhaseCC(128),
tremeloStrengthCC(128)
//midiInput(String())
//      gainParam (nullptr),
//      delayParam (nullptr),
//      delayPosition (0)
{
    lastPosInfo.resetToDefault();
    
    // This creates our parameters. We'll keep some raw pointers to them in this class,
    // so that we can easily access them later, but the base class will take care of
    // deleting them for us.
//    addParameter (gainParam  = new AudioParameterFloat ("gain",  "Gain",           0.0f, 1.0f, 0.9f));
//    addParameter (delayParam = new AudioParameterFloat ("delay", "Delay Feedback", 0.0f, 1.0f, 0.5f));
    
    initialiseSynth();
}

JuceDemoPluginAudioProcessor::~JuceDemoPluginAudioProcessor()
{
}



void JuceDemoPluginAudioProcessor::initialiseSynth()
{
    

    // Add some voices...
    for (int i = nVoices; --i >= 0;) {
        synth.addVoice (new SineWaveVoice());
    }
    // ..and give the synth a sound to play
    synth.clearSounds();
    synth.addSound (new FMSound());
}

//==============================================================================
void JuceDemoPluginAudioProcessor::prepareToPlay (double newSampleRate, int /*samplesPerBlock*/)
{
    // Use this method as the place to do any pre-playback
    // initialisation that you need..
    synth.setCurrentPlaybackSampleRate (newSampleRate);
//    keyboardState.reset();
    
 //   midiCollector.reset(newSampleRate);
    
 //   audioDeviceManager.initialise(getTotalNumInputChannels(), getTotalNumOutputChannels(), nullptr, true, String(), nullptr);
    
//    audioDeviceManager.initialiseWithDefaultDevices(getTotalNumInputChannels(), getTotalNumOutputChannels());
    
    
//    audioDeviceManager.addMidiInputCallback(String(), &midiCollector);
    
    

    if (isUsingDoublePrecision())
    {
//        delayBufferDouble.setSize (2, 12000);
//        delayBufferFloat.setSize (1, 1);
    }
    else
    {
//        delayBufferFloat.setSize (2, 12000);
//        delayBufferDouble.setSize (1, 1);
    }

    reset();
}

void JuceDemoPluginAudioProcessor::releaseResources()
{
    // When playback stops, you can use this as an opportunity to free up any
    // spare memory, etc.
    keyboardState.reset();
}

void JuceDemoPluginAudioProcessor::reset()
{
    // Use this method as the place to clear any delay lines, buffers, etc, as it
    // means there's been a break in the audio's continuity.
//    delayBufferFloat.clear();
//    delayBufferDouble.clear();
}

template <typename FloatType>
void JuceDemoPluginAudioProcessor::process (AudioBuffer<FloatType>& buffer,
                                            MidiBuffer& midiMessages)
{
    const int numSamples = buffer.getNumSamples();
//    buffer.clearActiveBufferRegion();
    
    

    // apply our gain-change to the incoming data..
 //   applyGain (buffer, delayBuffer);

    // Now pass any incoming midi messages to our keyboard state object, and let it
    // add messages to the buffer if the user is clicking on the on-screen keys
//    MidiBuffer incomingMidi;
//    midiCollector.removeNextBlockOfMessages(incomingMidi, numSamples);
    
 //   Debug midi message
    
    keyboardState.processNextMidiBuffer (midiMessages, 0, numSamples, true);
    //   handleIn
    
    // and now get our synth to process these midi events and generate its output.
    synth.renderNextBlock (buffer, midiMessages, 0, numSamples);
    
    
    MidiBuffer::Iterator i (midiMessages);
    MidiMessage message;
    int time;
    while(i.getNextEvent(message, time)) {
        
 //       DBG("Processor midiMessage handler called");
        if(message.isPitchWheel()){
            float halfsteps = ((float)message.getPitchWheelValue() * 4 / 16383) - 2;
            for (int i = 0; i < nVoices; ++i) {
//                DBG("PB in halfsteps" << halfsteps);
                 synth.getVoice(i)->faustParameterChanged("pitchBend", halfsteps);
            }
        }
        if(message.isController()){
            int nVoices = synth.getNumVoices();
            if(message.getControllerNumber() == 1) {
                float modbend =(float)message.getControllerValue()/127;
 //               DBG("ModWheel: "<<modbend);
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("modWheel", modbend);
                }
            }
            if(message.getControllerNumber() > 1 && learning) {
                assignCC = message.getControllerNumber();
 //               DBG("AssignCC = " << assignCC);
                
            }
            if(message.getControllerNumber() == attackCC){
                float attVal =(float)message.getControllerValue()/127*1.99+0.01;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("attack", attVal);
                }
                //attackSlider.setValue((float)message.getControllerValue()/127*1.99+0.01, dontSendNotification);
            }
            if(message.getControllerNumber() == decayCC) {
                float decVal = (float)message.getControllerValue()/127*1.99+0.01;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("decay", decVal);
                }
            }
            if(message.getControllerNumber() == sustainCC) {
                float susVal = (float)message.getControllerValue()/127*100;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("sustain", susVal);
                }
            }
            if(message.getControllerNumber() == releaseCC) {
                float relVal =(float)message.getControllerValue()/127*3.999+0.001;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("release", relVal);
                }
            }
            if(message.getControllerNumber() == cutoffCC) {
                float cutVal = (float)message.getControllerValue()/127*8+1;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("cutoff", cutVal);
                }
            }
            if(message.getControllerNumber() == QCC) {
                float QVal = (float)message.getControllerValue()/127*19+1;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("Q", QVal);
                }
            }
            if(message.getControllerNumber() == vibratoRateCC) {
                float vrVal = (float)message.getControllerValue()/127*10+2;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("vibRate", vrVal);
                }
            }
            if(message.getControllerNumber() == vibratoPhaseCC) {
                float vpVal = (float)message.getControllerValue()/127;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("vibPhase", vpVal);
                }
            }
            if(message.getControllerNumber() == vibratoStrengthCC) {
                float vsVal = (float)message.getControllerValue()/127;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("vibStr", vsVal);
                }
            }
            if(message.getControllerNumber() == tremeloRateCC) {
                float trVal = (float)message.getControllerValue()/127*10+2;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("tremRate", trVal);
                }
            }
            if(message.getControllerNumber() == tremeloPhaseCC) {
                float tpVal = (float)message.getControllerValue()/127;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("tremPhase", tpVal);
                }
            }
            if(message.getControllerNumber() == tremeloStrengthCC) {
                float tsVal = (float)message.getControllerValue()/127;
                for (int i = 0; i < nVoices; ++i) {
                    synth.getVoice(i)->faustParameterChanged("tremStr", tsVal);
                }
            }
        }

        
        
 //       handleIncomingMidiMessage(, message);
 //       DBG("MidiMessage received");
 //       DBG("MidiMessage timestamp" << time);
    }
    
    
 //   midiCollector.removeNextBlockOfMessages(midiMessages, numSamples);
 //   DBG("Buffer sample 0: " << buffer[0][0]);

    // Apply our delay effect to the new output..
//    applyDelay (buffer, delayBuffer);

    // In case we have more outputs than inputs, we'll clear any output
    // channels that didn't contain input data, (because these aren't
    // guaranteed to be empty - they may contain garbage).
//    for (int i = getTotalNumInputChannels(); i < getTotalNumOutputChannels(); ++i)
//        buffer.clear (i, 0, numSamples);

    // Now ask the host for the current time so we can store it to be displayed later...
    updateCurrentTimeInfoFromHost();
}





//template <typename FloatType>
//void JuceDemoPluginAudioProcessor::applyGain (AudioBuffer<FloatType>& buffer, AudioBuffer<FloatType>& delayBuffer)
//{
//    ignoreUnused (delayBuffer);
//    const float gainLevel = *gainParam;
//
//    for (int channel = 0; channel < getTotalNumInputChannels(); ++channel)
//        buffer.applyGain (channel, 0, buffer.getNumSamples(), gainLevel);
//}

//template <typename FloatType>
//void JuceDemoPluginAudioProcessor::applyDelay (AudioBuffer<FloatType>& buffer, AudioBuffer<FloatType>& delayBuffer)
//{
//    const int numSamples = buffer.getNumSamples();
//    const float delayLevel = *delayParam;
//
//    int delayPos = 0;
//
//    for (int channel = 0; channel < getTotalNumInputChannels(); ++channel)
//    {
//        FloatType* const channelData = buffer.getWritePointer (channel);
//        FloatType* const delayData = delayBuffer.getWritePointer (jmin (channel, delayBuffer.getNumChannels() - 1));
//        delayPos = delayPosition;
//
//        for (int i = 0; i < numSamples; ++i)
//        {
//            const FloatType in = channelData[i];
//            channelData[i] += delayData[delayPos];
//            delayData[delayPos] = (delayData[delayPos] + in) * delayLevel;
//
//            if (++delayPos >= delayBuffer.getNumSamples())
//                delayPos = 0;
//        }
//    }
//
//    delayPosition = delayPos;
//}
//void JuceDemoPluginAudioProcessor:: handleMidiMessage (const MidiMessage& message) {
//    DBG("Processor midiMessage handler called");
//    if(message.isController()){
//        int nVoices = synth.getNumVoices();
//        if(message.getControllerNumber() == 1) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("modWheel", message.getControllerValue()/127);
//            }
//        }
//        if(message.getControllerNumber() > 1 && learning) {
//            assignCC = message.getControllerNumber();
//            DBG("AssignCC = " << assignCC);
//            
//        }
//        if(message.getControllerNumber() == attackCC){
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("attack", (float)message.getControllerValue()/127*1.99+0.01);
//            }
//            //attackSlider.setValue((float)message.getControllerValue()/127*1.99+0.01, dontSendNotification);
//        }
//        if(message.getControllerNumber() == decayCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("decay", (float)message.getControllerValue()/127*1.99+0.01);
//            }
//        }
//        if(message.getControllerNumber() == sustainCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("sustain", (float)message.getControllerValue()/127*100);
//            }
//        }
//        if(message.getControllerNumber() == releaseCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("release", (float)message.getControllerValue()/127*3.999+0.001);
//            }
//        }
//        if(message.getControllerNumber() == cutoffCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("cutoff", (float)message.getControllerValue()/127*7980+20);
//            }
//        }
//        if(message.getControllerNumber() == QCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("Q", (float)message.getControllerValue()/127*19+1);
//            }
//        }
//        if(message.getControllerNumber() == vibratoRateCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("vibRate", (float)message.getControllerValue()/127*10+2);
//            }
//        }
//        if(message.getControllerNumber() == vibratoPhaseCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("vibPhase", (float)message.getControllerValue()/127);
//            }
//        }
//        if(message.getControllerNumber() == vibratoStrengthCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("vibStr", (float)message.getControllerValue()/127);
//            }
//        }
//        if(message.getControllerNumber() == tremeloRateCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("tremRate", (float)message.getControllerValue()/127*10+2);
//            }
//        }
//        if(message.getControllerNumber() == tremeloPhaseCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("tremPhase", (float)message.getControllerValue()/127);
//            }
//        }
//        if(message.getControllerNumber() == tremeloStrengthCC) {
//            for (int i = 0; i < nVoices; ++i) {
//                synth.getVoice(i)->faustParameterChanged("tremStr", (float)message.getControllerValue()/127);
//            }
//        }
//    }
//}

    void JuceDemoPluginAudioProcessor::updateCurrentTimeInfoFromHost()
    {
    if (AudioPlayHead* ph = getPlayHead())
    {
        AudioPlayHead::CurrentPositionInfo newTime;

        if (ph->getCurrentPosition (newTime))
        {
            lastPosInfo = newTime;  // Successfully got the current time from the host..
            return;
        }
    }

    // If the host fails to provide the current time, we'll just reset our copy to a default..
    lastPosInfo.resetToDefault();
}

//==============================================================================
AudioProcessorEditor* JuceDemoPluginAudioProcessor::createEditor()
{
    return new JuceDemoPluginAudioProcessorEditor (*this);
}

//==============================================================================
void JuceDemoPluginAudioProcessor::getStateInformation (MemoryBlock& destData)
{
    // You should use this method to store your parameters in the memory block.
    // Here's an example of how you can use XML to make it easy and more robust:

    // Create an outer XML element..
    XmlElement xml ("MYPLUGINSETTINGS");

    // add some attributes to it..
    xml.setAttribute ("uiWidth", lastUIWidth);
    xml.setAttribute ("uiHeight", lastUIHeight);

    // Store the values of all our parameters, using their param ID as the XML attribute
    for (int i = 0; i < getNumParameters(); ++i)
        if (AudioProcessorParameterWithID* p = dynamic_cast<AudioProcessorParameterWithID*> (getParameters().getUnchecked(i)))
            xml.setAttribute (p->paramID, p->getValue());

    // then use this helper function to stuff it into the binary blob and return it..
    copyXmlToBinary (xml, destData);
}

void JuceDemoPluginAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
    // You should use this method to restore your parameters from this memory block,
    // whose contents will have been created by the getStateInformation() call.

    // This getXmlFromBinary() helper function retrieves our XML from the binary blob..
    ScopedPointer<XmlElement> xmlState (getXmlFromBinary (data, sizeInBytes));

    if (xmlState != nullptr)
    {
        // make sure that it's actually our type of XML object..
        if (xmlState->hasTagName ("MYPLUGINSETTINGS"))
        {
            // ok, now pull out our last window size..
            lastUIWidth  = jmax (xmlState->getIntAttribute ("uiWidth", lastUIWidth), 400);
            lastUIHeight = jmax (xmlState->getIntAttribute ("uiHeight", lastUIHeight), 200);

            // Now reload our parameters..
            for (int i = 0; i < getNumParameters(); ++i)
                if (AudioProcessorParameterWithID* p = dynamic_cast<AudioProcessorParameterWithID*> (getParameters().getUnchecked(i)))
                    p->setValueNotifyingHost ((float) xmlState->getDoubleAttribute (p->paramID, p->getValue()));
        }
    }
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new JuceDemoPluginAudioProcessor();
}
